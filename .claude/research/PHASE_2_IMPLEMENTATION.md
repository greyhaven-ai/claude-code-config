# Phase 2 Implementation: Agent Quality Gates

**Date**: 2025-11-09
**Status**: ‚úÖ IMPLEMENTED
**Version**: 1.0

## Overview

Successfully implemented Phase 2 of the prompt-based hooks roadmap, focusing on agent quality gates to ensure comprehensive, high-quality work completion from specialized agents.

## What Was Implemented

### Hook 3: TDD Completion Validator

**Event Type**: SubagentStop
**Agent Names**: tdd-orchestrator, tdd-python, tdd-typescript
**Timeout**: 30 seconds
**Priority**: üî¥ HIGH

**Purpose**: Ensures test-driven development agents complete all three phases (RED-GREEN-REFACTOR) with proper coverage and quality standards.

**Validation Criteria**:

#### **RED Phase (Failing Test)**
- ‚úì Test written FIRST (before implementation)
- ‚úì Test fails for RIGHT REASON (not syntax/import errors)
- ‚úì Assertions are SPECIFIC and MEANINGFUL
- ‚úì Test name is DESCRIPTIVE

#### **GREEN Phase (Minimal Implementation)**
- ‚úì MINIMAL code to make test pass
- ‚úì Test actually PASSES
- ‚úì Over-engineering AVOIDED

#### **REFACTOR Phase (Code Improvement)**
- ‚úì Code refactored for clarity/quality
- ‚úì All tests STILL PASS
- ‚úì Coverage MAINTAINED or IMPROVED

#### **Coverage & Quality Gates**
- Line coverage ‚â• 80% OR delta coverage = 100%
- Branch coverage ‚â• 75%
- Critical path coverage = 100% (if applicable)
- Mutation score ‚â• 85% (if mutation testing mentioned)
- No test smells (brittle assertions, interdependence)

**Decision Logic**:

| Condition | Decision | Example |
|-----------|----------|---------|
| RED phase skipped | ‚ùå BLOCK | Test written after implementation |
| Test didn't fail initially | ‚ùå BLOCK | Test passed immediately |
| Coverage <80% line | ‚ùå BLOCK | Only 73% line coverage |
| Tests failing | ‚ùå BLOCK | 2 tests failing |
| All 3 phases complete + coverage met | ‚úÖ APPROVE | RED‚ÜíGREEN‚ÜíREFACTOR, 87% coverage |

**Example Output**:

```
‚úÖ TDD Cycle Complete

RED: test_user_login_valid_credentials failed correctly
GREEN: Minimal implementation, test passes
REFACTOR: Code improved, tests still passing

Coverage: 87% line, 82% branch ‚úÖ
Mutation score: 91% ‚úÖ

Great work maintaining TDD discipline!
```

### Hook 4: Security Analysis Completion Validator

**Event Type**: SubagentStop
**Agent Names**: security-analyzer
**Timeout**: 30 seconds
**Priority**: üî¥ HIGH

**Purpose**: Ensures security analysis agents perform comprehensive OWASP Top 10 audits with proper scoring and remediation plans.

**Validation Criteria**:

#### **OWASP Top 10 Coverage** (ALL 10 Required)
1. ‚úì A01: Broken Access Control
2. ‚úì A02: Cryptographic Failures
3. ‚úì A03: Injection
4. ‚úì A04: Insecure Design
5. ‚úì A05: Security Misconfiguration
6. ‚úì A06: Vulnerable Components
7. ‚úì A07: Authentication Failures
8. ‚úì A08: Data Integrity Failures
9. ‚úì A09: Security Logging Failures
10. ‚úì A10: Server-Side Request Forgery

#### **Critical Findings Checklist**
- ‚úì All Critical (CVSS 9.0+) vulnerabilities identified
- ‚úì Specific remediations for each finding
- ‚úì CVSS scores calculated
- ‚úì Exploit scenarios documented
- ‚úì Compliance mapping (PCI DSS, GDPR, etc.)

#### **Secret Detection**
- ‚úì Scanned for hardcoded credentials
- ‚úì Checked for API keys/tokens
- ‚úì Reviewed for private keys

#### **Dependency Security**
- ‚úì Ran dependency scanner (npm audit, pip-audit, etc.)
- ‚úì Identified vulnerable packages
- ‚úì Provided upgrade paths

**Decision Logic**:

| Condition | Decision | Example |
|-----------|----------|---------|
| Any OWASP category skipped | ‚ùå BLOCK | Only 7/10 categories checked |
| Critical vulns unresolved | ‚ùå BLOCK | CVSS 9.5 SQL injection, no remediation |
| No CVSS scores | ‚ùå BLOCK | Vulnerabilities found but not scored |
| Dependency scan not run | ‚ùå BLOCK | No npm audit/pip-audit output |
| All 10 categories + remediations | ‚úÖ APPROVE | Comprehensive audit complete |

**Example Output**:

```
‚úÖ Security Audit Complete

OWASP Top 10: 10/10 ‚úÖ
Findings: 2 Critical, 5 High, 12 Medium, 8 Low
CVSS Scoring: Complete ‚úÖ
Remediation Plans: Complete ‚úÖ

Security Score: 78/100
Recommendation: Requires fixes before production deployment
```

### Hook 5: Debug Resolution Validator

**Event Type**: SubagentStop
**Agent Names**: smart-debug
**Timeout**: 30 seconds
**Priority**: üî¥ HIGH

**Purpose**: Ensures debugging agents identify root causes (not just symptoms), create regression tests, and document prevention strategies.

**Validation Criteria**:

#### **Root Cause Analysis (5 Whys)**
- ‚úì Surface symptom identified
- ‚úì Immediate cause identified
- ‚úì Underlying cause identified
- ‚úì Root cause identified (Why #5)
- ‚úì Contributing factors identified

**Example 5 Whys**:
```
Symptom: User registration fails with 500 error
Why 1: Database constraint violation
Why 2: Duplicate email addresses
Why 3: Multiple form submissions
Why 4: Submit button not disabled
Why 5: Missing client-side debouncing

Root Cause: Frontend missing submit button debounce
```

#### **Test-Driven Debugging**
1. ‚úì Failing test created to reproduce bug
2. ‚úì Test initially failed (confirms reproduction)
3. ‚úì Fix applied
4. ‚úì Test now passes
5. ‚úì Full test suite still passes (no regressions)

#### **Fix Quality**
- ‚úì Addresses ROOT CAUSE (not symptom)
- ‚úì Minimal change (surgical fix)
- ‚úì No side effects introduced
- ‚úì Code quality maintained
- ‚úì Documentation updated

#### **Prevention Strategy**
1. ‚úì Regression test added (test_[bug_description])
2. ‚úì Monitoring/alerting added (if production bug)
3. ‚úì Input validation improved (if applicable)
4. ‚úì Error handling enhanced (if applicable)
5. ‚úì Documentation/runbook updated

**Decision Logic**:

| Condition | Decision | Example |
|-----------|----------|---------|
| No root cause analysis | ‚ùå BLOCK | Only symptom fixed, no 5 Whys |
| No failing test created | ‚ùå BLOCK | Bug fixed without test |
| Tests still failing | ‚ùå BLOCK | Fix applied but tests fail |
| No prevention strategy | ‚ùå BLOCK | No regression test or monitoring |
| Root cause + test + prevention | ‚úÖ APPROVE | Complete bug fix workflow |

**Example Output**:

```
‚úÖ Bug Fix Complete

Root Cause: Frontend missing submit button debounce (via 5 Whys)
Fix: Added 2-second debounce to registration form
Test: test_duplicate_submission_prevented ‚úÖ (created and passing)
Regression Suite: All 127 tests passing ‚úÖ
Prevention: Added client-side debouncing + integration test

Bug resolved and won't recur. Excellent debugging work!
```

## Implementation Details

### Configuration Location

**File**: `.claude/settings.json`

```json
{
  "hooks": {
    "PreToolUse": [...], // Phase 1 hooks
    "SubagentStop": [
      {
        "name": "tdd-completion-validator",
        "description": "Validates TDD red-green-refactor cycle completion",
        "hooks": [{
          "type": "prompt",
          "prompt": "...",
          "timeout": 30
        }],
        "agentNames": ["tdd-orchestrator", "tdd-python", "tdd-typescript"]
      },
      {
        "name": "security-analysis-completion",
        "description": "Validates comprehensive OWASP Top 10 security audit",
        "hooks": [{
          "type": "prompt",
          "prompt": "...",
          "timeout": 30
        }],
        "agentNames": ["security-analyzer"]
      },
      {
        "name": "debug-resolution-validator",
        "description": "Validates bug fix with root cause analysis and prevention",
        "hooks": [{
          "type": "prompt",
          "prompt": "...",
          "timeout": 30
        }],
        "agentNames": ["smart-debug"]
      }
    ]
  }
}
```

### How It Works

1. **Trigger**: When TDD, security-analyzer, or smart-debug agents attempt to stop
2. **Hook Execution**:
   - Prompt-based hook sends agent context + task to Haiku LLM
   - LLM evaluates completion against domain-specific criteria
   - Returns JSON decision (approve/block)
3. **Action**: Claude Code enforces decision
   - **approve**: Agent stops, work considered complete
   - **block**: Agent prevented from stopping, must continue
4. **Feedback**: Clear explanation of what's missing and required actions

### Prompt Engineering

All Phase 2 hooks use:
- ‚úÖ **Domain expertise role** ("TDD methodology expert", "Security audit expert", "Debugging expert")
- ‚úÖ **Structured checklists** (RED-GREEN-REFACTOR, OWASP Top 10, 5 Whys)
- ‚úÖ **Explicit completion criteria** (coverage thresholds, all categories checked)
- ‚úÖ **Quality gates** (mutation score, CVSS scoring, prevention strategy)
- ‚úÖ **Specific feedback** (what's missing, required actions)
- ‚úÖ **Examples** (good vs bad RCA, complete vs incomplete cycles)

### Performance Characteristics

**Latency**:
- Expected: 1000-2500ms (Haiku model, longer prompts)
- Timeout: 30 seconds (more complex evaluation)
- Impact: Acceptable for SubagentStop (end of agent work)

**Cost**:
- Model: Haiku
- Input: ~600-900 tokens per hook execution (longer prompts)
- Output: ~100-200 tokens
- Cost per execution: ~$0.00015
- Monthly estimate (500 agent runs): ~$0.08

**Reliability**:
- Timeout protection: 30 seconds
- Fallback: On timeout, default to APPROVE (fail-open)
- Error handling: JSON validation, clear error messages

## Relationship to Existing Hooks

### Complementary to subagent-work-validator.py

**Existing Hook** (.claude/hooks/python/subagent-work-validator.py):
- **Type**: General-purpose validator
- **Checks**: Syntax errors, tests exist, docs exist
- **Scope**: All subagents

**Our Phase 2 Hooks**:
- **Type**: Domain-specific validators
- **Checks**: TDD methodology, OWASP coverage, root cause analysis
- **Scope**: Specific agents (tdd-*, security-analyzer, smart-debug)

**Why Both Are Valuable**:

| Aspect | General Validator | Phase 2 Validators |
|--------|------------------|-------------------|
| **Purpose** | Basic quality checks | Domain-specific quality gates |
| **Coverage** | Code compiles, tests exist | Coverage thresholds, OWASP categories |
| **Detail** | "Tests added" | "80% coverage, mutation score 85%" |
| **Expertise** | General coding standards | TDD/Security/Debug methodology |

**Relationship**: **Complementary, not redundant**
- General validator: Baseline quality (all agents)
- Phase 2 validators: Domain expertise (specific agents)

## Testing

### Test Scenarios

#### **TDD Completion Validator**

**Should BLOCK**:
1. Test written after implementation (no RED phase)
2. Coverage 73% (below 80% threshold)
3. Tests failing (2 tests broken)
4. No mutation testing when mentioned
5. Brittle assertions (test implementation details)

**Should APPROVE**:
1. Complete RED‚ÜíGREEN‚ÜíREFACTOR cycle
2. Coverage 87% line, 82% branch
3. All tests passing
4. Mutation score 91%
5. High-quality assertions

#### **Security Analysis Completion**

**Should BLOCK**:
1. Only 7/10 OWASP categories checked
2. Critical vulnerability (CVSS 9.5) without remediation
3. No CVSS scores provided
4. Hardcoded secret detected but not addressed
5. Dependency scan not run

**Should APPROVE**:
1. All 10 OWASP categories checked
2. Critical findings have remediations
3. CVSS scoring complete
4. Secrets scanned, none found (or remediated)
5. Dependency scan complete with upgrade paths

#### **Debug Resolution Validator**

**Should BLOCK**:
1. Symptom fixed but no root cause analysis
2. No failing test created
3. Tests still failing after fix
4. No prevention strategy documented
5. Only 3 Whys (root cause not reached)

**Should APPROVE**:
1. Complete 5 Whys root cause analysis
2. Failing test created and now passes
3. Full test suite passes
4. Regression test + monitoring added
5. Documentation updated

### Manual Testing

Test the hooks by running agents:

```bash
# Test TDD completion validator
# Use tdd-orchestrator agent
# Scenario 1: Complete cycle (should approve)
# Scenario 2: Skip RED phase (should block)

# Test security analysis completion
# Use security-analyzer agent
# Scenario 1: All 10 OWASP categories (should approve)
# Scenario 2: Skip A10 SSRF (should block)

# Test debug resolution validator
# Use smart-debug agent
# Scenario 1: Root cause + test + prevention (should approve)
# Scenario 2: Just symptom fix (should block)
```

### Validation Checklist

- [x] ‚úÖ settings.json is valid JSON
- [x] ‚úÖ SubagentStop hooks configured correctly
- [x] ‚úÖ Agent names match actual agent definitions
- [x] ‚úÖ Prompts use $ARGUMENTS placeholder
- [x] ‚úÖ Response format is valid JSON schema
- [x] ‚úÖ Timeouts set appropriately (30s)
- [ ] ‚è≥ Tested TDD completion validation (pending agent usage)
- [ ] ‚è≥ Tested security analysis validation (pending agent usage)
- [ ] ‚è≥ Tested debug resolution validation (pending agent usage)
- [ ] ‚è≥ Measured hook latency (pending agent usage)
- [ ] ‚è≥ Validated false positive rate (pending agent usage)

## Success Metrics

### Phase 2 Goals

**Primary**:
- ‚úÖ 90%+ TDD cycles complete all three phases
- ‚úÖ 95%+ security audits cover all OWASP Top 10
- ‚úÖ 80%+ bugs fixed with root cause analysis and prevention
- ‚è≥ <5% false positive rate (to be measured)

**Secondary**:
- ‚è≥ Hook latency p95 <3s (to be measured)
- ‚è≥ Developer satisfaction >4/5 (to be surveyed)
- ‚è≥ Reduced bug recurrence rate (to be tracked)

### Monitoring

Track these metrics for each hook:

```javascript
{
  "hook": "tdd-completion-validator",
  "executions": 0,
  "decisions": {
    "approve": 0,
    "block": 0
  },
  "block_reasons": {
    "red_phase_skipped": 0,
    "coverage_below_threshold": 0,
    "tests_failing": 0,
    "refactor_phase_incomplete": 0
  },
  "latency_p95": 0,
  "agent_retries": 0  // How often agent continued after block
}
```

## Integration with Existing Ecosystem

### Comparison with Bash Hook

**Existing**: `.claude/hooks/python/subagent-work-validator.py`

```python
# General checks (bash)
- Code compiles
- Tests exist
- Docs exist
```

**Phase 2 Hooks** (prompt-based):

```
# Domain-specific checks (LLM)
TDD: RED‚ÜíGREEN‚ÜíREFACTOR, 80% coverage, mutation testing
Security: OWASP Top 10, CVSS scoring, dependency scan
Debug: 5 Whys, regression test, prevention strategy
```

**Result**: **Hybrid approach**
- Bash hook: Fast, deterministic baseline checks
- Phase 2 hooks: Smart, domain-specific quality gates

### Agent Documentation Updates

Agents should document their hook integration:

**Example** (grey-haven-plugins/core/agents/tdd-orchestrator.md):

```markdown
## Hook Integration

### SubagentStop Hook: TDD Completion Validator

This agent integrates with a prompt-based completion validator that enforces:
- RED-GREEN-REFACTOR cycle completion
- Coverage thresholds (80% line, 75% branch)
- Test quality and mutation testing

If the hook blocks completion, review:
- Did you complete all three TDD phases?
- Are coverage thresholds met? (Run coverage report)
- Are test assertions specific and meaningful?
- Did mutation testing run (if applicable)?
```

## Known Limitations

### Current Limitations

1. **Context Awareness**:
   - LLM sees task description but not full agent transcript
   - May miss nuances in agent's work
   - **Mitigation**: Pass summary of agent's key outputs

2. **Latency**:
   - 1000-2500ms added to agent completion
   - Longer than Phase 1 hooks
   - **Mitigation**: Acceptable for SubagentStop (end of work)

3. **False Positives**:
   - May block when agent completed work differently than expected
   - Example: Coverage calculated differently
   - **Mitigation**: Monitor block reasons, tune prompts

4. **Agent Variability**:
   - Different TDD agents may report differently
   - Hook must handle varied output formats
   - **Mitigation**: Flexible prompt interpretation

### Future Enhancements

**Short term** (next 2 weeks):
- Add agent transcript summary to prompts
- Implement hook execution logging
- Create agent-specific tuning

**Medium term** (next month):
- Add conversation history for better context
- Implement adaptive thresholds (per project)
- Create hook bypass mechanism (emergency use)

**Long term** (next quarter):
- Machine learning on approval/block patterns
- Agent-specific quality profiles
- Integration with CI/CD for metrics

## Rollout Plan

### Phase 2A: Internal Testing (Week 1)

- [x] ‚úÖ Implement SubagentStop hooks
- [ ] ‚è≥ Test with Grey Haven team using agents
- [ ] ‚è≥ Collect feedback on block decisions
- [ ] ‚è≥ Measure latency and false positive rate
- [ ] ‚è≥ Tune prompts based on real usage

### Phase 2B: Limited Release (Week 2)

- [ ] ‚è≥ Enable for 20% of agent usage
- [ ] ‚è≥ Monitor metrics dashboard
- [ ] ‚è≥ Track quality improvements (coverage, OWASP, RCA)
- [ ] ‚è≥ Address high-priority issues

### Phase 2C: Full Release (Week 3)

- [ ] ‚è≥ Enable for 100% of agent usage
- [ ] ‚è≥ Update agent documentation
- [ ] ‚è≥ Announce to community
- [ ] ‚è≥ Monitor quality metrics

### Phase 2D: Optimization (Week 4)

- [ ] ‚è≥ Analyze 1 month of data
- [ ] ‚è≥ Tune prompts to reduce false positives
- [ ] ‚è≥ Implement top feature requests
- [ ] ‚è≥ Prepare for Phase 3 (Code Quality)

## Documentation

### User-Facing Docs

**To be created**:

1. **Agent Quality Gates Guide**: `docs/hooks/AGENT_QUALITY_GATES.md`
   - What are SubagentStop hooks?
   - How do they ensure quality?
   - What to do if blocked?
   - How to interpret feedback?

2. **TDD Completion Guide**: `docs/hooks/TDD_COMPLETION_REQUIREMENTS.md`
   - RED-GREEN-REFACTOR requirements
   - Coverage threshold explanations
   - Mutation testing guide
   - Common blocking reasons

3. **Security Audit Guide**: `docs/hooks/SECURITY_AUDIT_REQUIREMENTS.md`
   - OWASP Top 10 checklist
   - CVSS scoring guide
   - Dependency scanning requirements
   - Common blocking reasons

4. **Debug Quality Guide**: `docs/hooks/DEBUG_QUALITY_REQUIREMENTS.md`
   - 5 Whys methodology
   - Root cause vs symptom
   - Prevention strategy examples
   - Common blocking reasons

### Developer Docs

**Research Documents** (5 total):
1. ‚úÖ `PROMPT_BASED_HOOKS_ANALYSIS.md` - Original analysis
2. ‚úÖ `PROMPT_HOOKS_IMPLEMENTATION_EXAMPLES.md` - Configuration examples
3. ‚úÖ `HOOKS_DISCOVERY_IMPACT_ANALYSIS.md` - 41 hooks discovered
4. ‚úÖ `PHASE_1_IMPLEMENTATION.md` - Phase 1 (Critical Safety)
5. ‚úÖ `PHASE_2_IMPLEMENTATION.md` - **NEW** - Phase 2 (Agent Quality Gates)

## Next Steps

### Immediate (This Week)

1. ‚úÖ Implement Phase 2 hooks in settings.json
2. ‚úÖ Document implementation
3. ‚è≥ Test hooks with actual agent usage
4. ‚è≥ Measure latency and behavior
5. ‚è≥ Commit and push implementation

### Short Term (Next 2 Weeks)

6. ‚è≥ Gather team feedback from agent usage
7. ‚è≥ Tune prompts based on false positives
8. ‚è≥ Add metrics collection
9. ‚è≥ Create user documentation
10. ‚è≥ Begin Phase 3 planning (Code Quality)

### Medium Term (Next Month)

11. ‚è≥ Full rollout to all users
12. ‚è≥ Implement Phase 3 (Code Quality & Testing)
13. ‚è≥ Track quality improvements
14. ‚è≥ Optimize performance

## Conclusion

### Implementation Summary

‚úÖ **Successfully implemented Phase 2** of prompt-based hooks roadmap:
- TDD Completion Validator (SubagentStop)
- Security Analysis Completion Validator (SubagentStop)
- Debug Resolution Validator (SubagentStop)

‚úÖ **Configuration added** to `.claude/settings.json`

‚úÖ **Documentation complete** for Phase 2 specifications

‚è≥ **Testing in progress** - awaiting real agent usage

### Impact Assessment

**Expected impact**:
- üî¥ **90%+ TDD cycles complete** all three phases (RED-GREEN-REFACTOR)
- üî¥ **95%+ security audits** cover all OWASP Top 10 categories
- üî¥ **80%+ bug fixes** include root cause analysis and prevention
- üü° **<3s latency** for quality gate checks (acceptable for SubagentStop)
- üü¢ **<5% false positive rate** (to be validated)

**Quality enforcement**:
- ‚úÖ TDD discipline: Coverage thresholds, test quality, mutation testing
- ‚úÖ Security thoroughness: OWASP categories, CVSS scoring, dependency scanning
- ‚úÖ Debug quality: Root cause (5 Whys), regression tests, prevention strategies

### Readiness Status

**Status**: ‚úÖ **READY FOR TESTING**

**Pending**:
- Agent usage testing (TDD, security, debug workflows)
- Latency measurement
- False positive rate validation
- User feedback collection

**Comparison to Phase 1**:

| Aspect | Phase 1 (Critical Safety) | Phase 2 (Agent Quality) |
|--------|-------------------------|------------------------|
| Event Type | PreToolUse | SubagentStop |
| Focus | Prevent accidents | Enforce quality |
| Trigger | Before tool execution | After agent completes |
| Validators | 2 hooks | 3 hooks |
| Latency | 800-2000ms | 1000-2500ms |
| Impact | Safety | Quality |

**Next Phase**: Phase 3 - Code Quality & Testing (Stop hooks, PreToolUse enhancements)

---

**Last Updated**: 2025-11-09
**Status**: Implementation Complete, Testing Pending
**Phase**: 2 of 5 (Agent Quality Gates)
**Priority**: üî¥ HIGH
